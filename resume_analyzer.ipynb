{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # **RESUME EVALUATOR**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project evaluates resumes by extracting skills, education, and experience using NLP techniques. It also calculates an ATS (Applicant Tracking System) score and suggests improvements based on missing skills.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: Install Dependencies**\n",
    "\n",
    "We need to install required libraries before running the project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk spacy pdfminer.six\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Import Required Libraries**\n",
    "\n",
    "We import essential libraries for text extraction, tokenization, stopword removal, and Named Entity Recognition (NER).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from pdfminer.high_level import extract_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download necessary NLTK datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Spacy NLP model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Extract Text from PDF Resume**\n",
    "\n",
    "We extract text from a given PDF resume file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_resume_text(pdf_path):\n",
    "    text = extract_text(pdf_path)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: NLP Preprocessing**\n",
    "\n",
    "We perform tokenization and stopword removal to clean the resume text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_resume(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    filtered_tokens = [word.lower() for word in tokens if word.isalpha() and word.lower() not in stop_words]\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: Named Entity Recognition (NER)**\n",
    "\n",
    "We use NER to extract important resume sections such as skills, education, and experience.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entities = {\"skills\": [], \"education\": [], \"experience\": []}\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in [\"ORG\", \"WORK_OF_ART\"]:\n",
    "            entities[\"skills\"].append(ent.text)\n",
    "        elif ent.label_ == \"DATE\":\n",
    "            entities[\"experience\"].append(ent.text)\n",
    "        elif ent.label_ == \"EDUCATION\":\n",
    "            entities[\"education\"].append(ent.text)\n",
    "    \n",
    "    return entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6: Calculate ATS Score**\n",
    "\n",
    "We compare extracted skills with an ideal skillset to compute an ATS score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_skills = [\"python\", \"machine learning\", \"data analysis\", \"nlp\", \"sql\", \"deep learning\", \"cloud computing\"]\n",
    "\n",
    "def calculate_score(extracted_skills):\n",
    "    match_count = sum(1 for skill in extracted_skills if skill.lower() in ideal_skills)\n",
    "    score = (match_count / len(ideal_skills)) * 100\n",
    "    return round(score, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 7: Suggest Resume Improvements**\n",
    "\n",
    "We identify missing skills and provide improvement suggestions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_improvements(extracted_skills):\n",
    "    missing_skills = [skill for skill in ideal_skills if skill.lower() not in extracted_skills]\n",
    "    return missing_skills if missing_skills else [\"Your resume is excellent!\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 8: Test the System with a Sample Resume PDF**\n",
    "\n",
    "We run the entire process on a sample resume and display the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    pdf_path = r\"C:\\Users\\UDIT\\Downloads\\resumeudit (4).pdf\" \n",
    "    resume_text = extract_resume_text(pdf_path)\n",
    "    tokens = preprocess_resume(resume_text)\n",
    "    entities = extract_entities(resume_text)\n",
    "    \n",
    "    score = calculate_score(entities[\"skills\"])\n",
    "    improvements = suggest_improvements(entities[\"skills\"])\n",
    "    \n",
    "    print(\"\\nResume Analysis Result:\")\n",
    "    print(f\"Extracted Skills: {entities['skills']}\")\n",
    "    print(f\"Extracted Education: {entities['education']}\")\n",
    "    print(f\"Extracted Experience: {entities['experience']}\")\n",
    "    print(f\"ATS Score: {score}%\")\n",
    "    print(f\"Suggested Improvements: {improvements}\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "- This project extracts text from resumes, cleans it, and applies NLP techniques to extract key details.\n",
    "- It calculates an ATS score based on relevant skills.\n",
    "- Finally, it suggests improvements to enhance the resume quality.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "g15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
